{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7217bf",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vanderbilt-data-science/ai-winter/blob/main/1_text_simple_classification_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4849f3-51e1-4299-9f55-9c70c1f1c431",
   "metadata": {
    "id": "8d4849f3-51e1-4299-9f55-9c70c1f1c431"
   },
   "source": [
    "# Fine-Tuning Models\n",
    "> An introductory example on fine-tuning models\n",
    "\n",
    "In this walkthrough, we'll explore the standard steps of fine-tuning a model, and we'll apply this towards the intuitive task of text classification.\n",
    "\n",
    "We'll leverage the [`tweet_eval` dataset](https://huggingface.co/datasets/tweet_eval) to try to classify emotions of tweets into relevant categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thJhDvdZF-3U",
   "metadata": {
    "id": "thJhDvdZF-3U"
   },
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abbc1b7-f4b4-4cdd-93ed-ce92742fe4c6",
   "metadata": {
    "id": "0abbc1b7-f4b4-4cdd-93ed-ce92742fe4c6"
   },
   "source": [
    "### Install required packages\n",
    "Note that this is mostly required if you're on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067752c-e281-4ffe-9140-828d158751a1",
   "metadata": {
    "id": "6067752c-e281-4ffe-9140-828d158751a1"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install transformers\n",
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4f46c-e1c0-4abc-9498-a45211bcf9a6",
   "metadata": {
    "id": "b4b4f46c-e1c0-4abc-9498-a45211bcf9a6"
   },
   "source": [
    "### Import packages of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa3949-c286-4a82-af4f-c5f7594a6c97",
   "metadata": {
    "id": "6afa3949-c286-4a82-af4f-c5f7594a6c97"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from transformers import pipeline\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6902fa8d-8192-4ab0-8f5f-9a0ddf6c34fd",
   "metadata": {
    "id": "6902fa8d-8192-4ab0-8f5f-9a0ddf6c34fd"
   },
   "source": [
    "## Log into HuggingFace CLI\n",
    "Why are we doing this? Below, we'll use our own user accounts to grab datasets and upload models. If we don't do this, we'll have to pass in the auth token over. This isn't bad, but let's streamline our efforts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75fd3d-76d2-425f-be19-aace4db0e71a",
   "metadata": {
    "id": "3a75fd3d-76d2-425f-be19-aace4db0e71a"
   },
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b6acb-bf9e-4e5c-8764-90eed505a2fb",
   "metadata": {
    "id": "9d0b6acb-bf9e-4e5c-8764-90eed505a2fb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a371ec-98f5-4be7-b085-a2eed2f9c3d3",
   "metadata": {
    "id": "d0a371ec-98f5-4be7-b085-a2eed2f9c3d3"
   },
   "source": [
    "# Load data from HuggingFace Hub, Datasets, or from disk\n",
    "\n",
    "In this example, we'll pull from the Huggingface Datasets repository. However, if you have your own dataset, you can use this here. We'll go over how to use your own datasets in future classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b6693-573c-4515-b3bc-0a70c43945c2",
   "metadata": {
    "id": "fc4b6693-573c-4515-b3bc-0a70c43945c2"
   },
   "outputs": [],
   "source": [
    "#Load tweet_eval dataset, emotion configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8Mg6MNhPIJl7",
   "metadata": {
    "id": "8Mg6MNhPIJl7"
   },
   "outputs": [],
   "source": [
    "# View general structure of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Za-YxO-0IOBG",
   "metadata": {
    "id": "Za-YxO-0IOBG"
   },
   "outputs": [],
   "source": [
    "# Look at an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z1qB-uJZIaSE",
   "metadata": {
    "id": "z1qB-uJZIaSE"
   },
   "outputs": [],
   "source": [
    "# Look at labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_O6dH3LYIjAD",
   "metadata": {
    "id": "_O6dH3LYIjAD"
   },
   "outputs": [],
   "source": [
    "# Create id2label, label2id, and standard info from datasets\n",
    "\n",
    "\n",
    "print(num_classes)\n",
    "print(id2label)\n",
    "label2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558ecf4-e35b-4afa-a1aa-ca16e86ab432",
   "metadata": {
    "id": "d558ecf4-e35b-4afa-a1aa-ca16e86ab432"
   },
   "source": [
    "# Pre-process inputs\n",
    "We've already learned about tokenizers - let's see what this looks like as we approach training. A richer treatment of tokenizers can be found in the Huggingface [instructions on tokenizers](https://huggingface.co/course/chapter2/4?fw=pt). Then, let's try it on our own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a7940-ae31-4efe-9398-93da6b2b0aa7",
   "metadata": {
    "id": "3d6a7940-ae31-4efe-9398-93da6b2b0aa7"
   },
   "outputs": [],
   "source": [
    "#instantiate tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d994af-196d-4dba-8c1b-95a75d8fa14b",
   "metadata": {
    "id": "68d994af-196d-4dba-8c1b-95a75d8fa14b"
   },
   "outputs": [],
   "source": [
    "#define tokenizing function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bc59e5-52b9-4449-8cda-bd94e88e980d",
   "metadata": {
    "id": "39bc59e5-52b9-4449-8cda-bd94e88e980d"
   },
   "outputs": [],
   "source": [
    "#do the tokenizing using map function\n",
    "tokenized_ds = demo_ds.map(tokenize_inputs, batched=True, remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061e38a-4e26-4294-8a3f-99f3a51de49a",
   "metadata": {
    "id": "2061e38a-4e26-4294-8a3f-99f3a51de49a"
   },
   "outputs": [],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15655b8b-45bb-4c3c-8ad8-dcd869beda5d",
   "metadata": {
    "id": "15655b8b-45bb-4c3c-8ad8-dcd869beda5d"
   },
   "source": [
    "## An aside on tokenizer functionality\n",
    "We can do many things with tokenizers to help us to tokenize our data and process it. Let's check out these outputs further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed0e3e-a3da-45b8-9c19-8749567c96fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fed0e3e-a3da-45b8-9c19-8749567c96fc",
    "outputId": "ae7b3fa5-8b67-4209-b4cf-9d56e4af6db6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 789, 160, 1766, 1616, 1110, 170, 1205, 7727, 1113, 170, 2463, 1128, 1336, 1309, 1138, 112, 119, 11882, 11545, 119, 108, 15710, 108, 3645, 108, 3994, 102]\n",
      "“Worry is a down payment on a problem you may never have'.  Joyce Meyer.  #motivation #leadership #worry\n"
     ]
    }
   ],
   "source": [
    "#check out input IDs\n",
    "print(tokenized_ds['train']['input_ids'][0])\n",
    "\n",
    "#compare against the text\n",
    "print(demo_ds['train']['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e1f43-5182-4094-880b-05a02c71d5b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "685e1f43-5182-4094-880b-05a02c71d5b1",
    "outputId": "91e2089a-d52f-432a-dc36-75c16de6047a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3257\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "#check out the length of the list of lists\n",
    "print(len(tokenized_ds['train']['input_ids']))\n",
    "\n",
    "#check out the length of a single element\n",
    "print(len(tokenized_ds['train']['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28141308-68b3-4f8e-affe-29b89118b201",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28141308-68b3-4f8e-affe-29b89118b201",
    "outputId": "a4a253b4-cadc-42d8-9861-9b7c4aa9a776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '“', 'W', '##or', '##ry', 'is', 'a', 'down', 'payment', 'on', 'a', 'problem', 'you', 'may', 'never', 'have', \"'\", '.', 'Joyce', 'Meyer', '.', '#', 'motivation', '#', 'leadership', '#', 'worry', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "#convert input_ids to token representation\n",
    "input0_tokens = tokenizer.convert_ids_to_tokens(tokenized_ds['train']['input_ids'][0])\n",
    "print(input0_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac4262-3678-4bf7-844a-f91d1f4d56fe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "51ac4262-3678-4bf7-844a-f91d1f4d56fe",
    "outputId": "3968303b-bf47-4a20-f378-4dafa4d9f163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] “ Worry is a down payment on a problem you may never have '. Joyce Meyer. # motivation # leadership # worry [SEP]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"[CLS] “ Worry is a down payment on a problem you may never have '. Joyce Meyer. # motivation # leadership # worry [SEP]\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see what this looks like as a string\n",
    "print(tokenizer.convert_tokens_to_string(input0_tokens))\n",
    "\n",
    "#another method directly from the input ids\n",
    "tokenizer.decode(tokenized_ds['train']['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af725b84-ab00-413b-aa84-36be19efd62f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "af725b84-ab00-413b-aa84-36be19efd62f",
    "outputId": "dcd64f5e-ce84-4323-8af0-aa39c78639fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ce9b23d5-8b5c-4c32-a240-d4ad220ed325\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inds</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15555</th>\n",
       "      <td>Scene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18102</th>\n",
       "      <td>Auxiliary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27474</th>\n",
       "      <td>##lanche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Ś</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>Genesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>corporate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685</th>\n",
       "      <td>erect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28478</th>\n",
       "      <td>##ث</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26174</th>\n",
       "      <td>##taining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5331</th>\n",
       "      <td>Ty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce9b23d5-8b5c-4c32-a240-d4ad220ed325')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ce9b23d5-8b5c-4c32-a240-d4ad220ed325 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ce9b23d5-8b5c-4c32-a240-d4ad220ed325');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "          tokens\n",
       "inds            \n",
       "15555      Scene\n",
       "18102  Auxiliary\n",
       "27474   ##lanche\n",
       "318            Ś\n",
       "12117    Genesis\n",
       "6214   corporate\n",
       "15685      erect\n",
       "28478        ##ث\n",
       "26174  ##taining\n",
       "5331          Ty"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#other information about tokenizer\n",
    "print(tokenizer.vocab_size)\n",
    "\n",
    "#see actual tokenizer vocab (we've abbreviated here)\n",
    "#tokenizer.vocab\n",
    "pd.DataFrame({'tokens': tokenizer.vocab.keys(), 'inds': tokenizer.vocab.values()}).set_index('inds').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08845526-78fb-4096-bb4b-1ca13c7eda12",
   "metadata": {
    "id": "08845526-78fb-4096-bb4b-1ca13c7eda12"
   },
   "source": [
    "## An aside on dynamically padded batch size\n",
    "HF has the capacity to dynamically pad your batches such that each input is only as long as any given input in the batch. This helps with memory.You can learn more [here](https://huggingface.co/course/chapter3/2?fw=pt). For now, we'll simply instantiate a data collator and use it during training to demonstrate how we can do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86dd09-500c-4a14-80c4-32d9a432c0dd",
   "metadata": {
    "id": "df86dd09-500c-4a14-80c4-32d9a432c0dd"
   },
   "outputs": [],
   "source": [
    "#Instantiate data collator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da664a0-b63c-450a-ae74-bab101d55ea1",
   "metadata": {
    "id": "3da664a0-b63c-450a-ae74-bab101d55ea1"
   },
   "source": [
    "# Model Training Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6051da-9e43-48f2-baed-65e34b6488fb",
   "metadata": {
    "id": "be6051da-9e43-48f2-baed-65e34b6488fb"
   },
   "source": [
    "## Define model and task architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606be9d-e38c-48dd-9a8b-73be81ab5d93",
   "metadata": {
    "id": "2606be9d-e38c-48dd-9a8b-73be81ab5d93"
   },
   "outputs": [],
   "source": [
    "# Choose the model type and instantiate it for the task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aDxfB0aPLbCt",
   "metadata": {
    "id": "aDxfB0aPLbCt"
   },
   "source": [
    "## Consideration of appropriate metrics\n",
    "\n",
    "What are good metrics for us to use for classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n6rZFDAiLm8j",
   "metadata": {
    "id": "n6rZFDAiLm8j"
   },
   "source": [
    "### From HF Datasets Metrics\n",
    "Some metrics are available to us through [HF Datasets Metrics repo](https://huggingface.co/metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zZYMo9vnLhWJ",
   "metadata": {
    "id": "zZYMo9vnLhWJ"
   },
   "outputs": [],
   "source": [
    "#load a metric\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "#define the metric behavior\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2K88VoaqL3bN",
   "metadata": {
    "id": "2K88VoaqL3bN"
   },
   "source": [
    "### Custom definitions\n",
    "We can also define our own. The function inputs are a tuple of logits and labels, and the function must return a dictionary of key-value pairs. The keys should be the name of the metric and the values should be the values of that metric. We'll see an example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee093f3-a6ff-4134-9009-d7eaaf8760a1",
   "metadata": {
    "id": "1ee093f3-a6ff-4134-9009-d7eaaf8760a1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # Calculate your own metrics here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ct5YQhNYNspN",
   "metadata": {
    "id": "Ct5YQhNYNspN"
   },
   "source": [
    "## Settings for Model Training\n",
    "Now, let's set some parameters that will govern the training loop of the model training. This includes practical considerations such as:\n",
    "* Where the model should be saved\n",
    "* Whether the model should be pushed to hub\n",
    "* How often to assess the performance of the model on the validation set\n",
    "\n",
    "As well as settings for neural network training, including:\n",
    "* Number of epochs to train\n",
    "* Learning rate\n",
    "* Optimizer parameters\n",
    "\n",
    "We do this through [TrainingArguments](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments) and the [Trainer class.](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer) Let's take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ymF80XDNrw8",
   "metadata": {
    "id": "1ymF80XDNrw8"
   },
   "outputs": [],
   "source": [
    "#set new training arguments\n",
    "training_args = TrainingArguments(\"bert-emotion\",\n",
    "                                  logging_strategy = \"epoch\",\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  save_strategy='epoch',\n",
    "                                  load_best_model_at_end = True,\n",
    "                                  metric_for_best_model='fscore',\n",
    "                                  greater_is_better=True,\n",
    "                                  per_device_train_batch_size = 4,\n",
    "                                  per_device_eval_batch_size = 4,\n",
    "                                  num_train_epochs=3,\n",
    "                                  push_to_hub=True,\n",
    "                                  hub_strategy='checkpoint',\n",
    "                                  report_to='all')\n",
    "\n",
    "#set data and functionality for trainer\n",
    "trainer = Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  tokenizer=tokenizer,\n",
    "                  data_collator=data_collator,\n",
    "                  train_dataset=tokenized_ds['train'],\n",
    "                  eval_dataset=tokenized_ds['validation'],\n",
    "                  compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oXe8fUReQyUu",
   "metadata": {
    "id": "oXe8fUReQyUu"
   },
   "source": [
    "# Train model\n",
    "Now, let's actually train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1-v71nXaQUlw",
   "metadata": {
    "id": "1-v71nXaQUlw"
   },
   "outputs": [],
   "source": [
    "#actually train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d06945-a25e-48b2-a0e9-a9cd2b6778e6",
   "metadata": {
    "id": "b4d06945-a25e-48b2-a0e9-a9cd2b6778e6"
   },
   "outputs": [],
   "source": [
    "#it's recommended to push the final version to HF after training completes.\n",
    "#Note that the code below takes FOREVER depending on the size of your model so you might consider NOT running\n",
    "#this line until the end of class\n",
    "#trainer.push_to_hub(commit_message='end of training 3 epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ba1189-3e5f-42ae-bfae-e79f85a439f5",
   "metadata": {
    "id": "b6ba1189-3e5f-42ae-bfae-e79f85a439f5"
   },
   "source": [
    "# Using trained model with `Trainer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bEnxWnAaZeNu",
   "metadata": {
    "id": "bEnxWnAaZeNu"
   },
   "source": [
    "\n",
    "## Evaluate\n",
    "We can assess the performance of the model over a large number of inputs (e.g., the test set). Here, we initially look at the performance of the training set to make sure the model _can_ learn from the data we've provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5bd0ec-ec3f-4f0f-b52f-70c19f6a79b7",
   "metadata": {
    "id": "bd5bd0ec-ec3f-4f0f-b52f-70c19f6a79b7"
   },
   "outputs": [],
   "source": [
    "#run model evaluation on train dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f6ec1-24fb-43f7-a52a-1cdab4861fc5",
   "metadata": {
    "id": "c81f6ec1-24fb-43f7-a52a-1cdab4861fc5"
   },
   "source": [
    "## Predict\n",
    "We can also use the model to predict and have the actual logits returned to us. This is helpful if we want to better inspect the performance of the model to consider consistent reasons for misclassifications and ideas on how to improve the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83797f24-bcfb-405d-9f3a-01c8b26fd7ba",
   "metadata": {
    "id": "83797f24-bcfb-405d-9f3a-01c8b26fd7ba"
   },
   "outputs": [],
   "source": [
    "#use trainer to predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZE9IW_R-rGt2",
   "metadata": {
    "id": "ZE9IW_R-rGt2"
   },
   "outputs": [],
   "source": [
    "#decide to create a confusion matrix, so import this knowledge\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_IBUkSlLflk1",
   "metadata": {
    "id": "_IBUkSlLflk1"
   },
   "outputs": [],
   "source": [
    "# Create a dataframe for inspection\n",
    "preds_df = pd.DataFrame({'pred_ids':np.argmax(preds.predictions, axis=-1),\n",
    "                         'label_ids':preds.label_ids,\n",
    "                         'text':demo_ds['train']['text']})\n",
    "display(preds_df.head())\n",
    "\n",
    "# Populate pred_labels\n",
    "preds_df['pred_labels'] = preds_df['pred_ids'].replace(id2label)\n",
    "preds_df['true_labels'] = preds_df['label_ids'].replace(id2label)\n",
    "\n",
    "# Define misclassified\n",
    "preds_df['is_misclassified'] = preds_df['pred_ids'] != preds_df['label_ids']\n",
    "display(preds_df.query('is_misclassified == True'))\n",
    "\n",
    "# Get confusion matrix\n",
    "ConfusionMatrixDisplay.from_predictions(preds_df['true_labels'], preds_df['pred_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0hOL8rb2tYNF",
   "metadata": {
    "id": "0hOL8rb2tYNF"
   },
   "outputs": [],
   "source": [
    "#an example of inspecting the results to see examples of incorrect labels\n",
    "preds_df.query(\"true_labels=='joy' and pred_labels=='anger'\")['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94abc5f1-076e-4167-9c85-26d77404797f",
   "metadata": {
    "id": "94abc5f1-076e-4167-9c85-26d77404797f"
   },
   "source": [
    "# Using your fine-tuned model\n",
    "You can use the model that you've saved locally or the model that you've pushed to hub within a pipeline. Let's see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0edf1e-7ce3-450e-97dc-4abee8e6a50c",
   "metadata": {
    "id": "ca0edf1e-7ce3-450e-97dc-4abee8e6a50c"
   },
   "outputs": [],
   "source": [
    "#create pipeline from your classifier\n",
    "\n",
    "\n",
    "#optionally, load from HF\n",
    "#emotion_classifier = pipeline('text-classification', model='charreaubell/bert-emotion', use_auth_token=True)\n",
    "\n",
    "#get output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c9088-d638-4c52-aa47-096fcc4e0065",
   "metadata": {
    "id": "fc9c9088-d638-4c52-aa47-096fcc4e0065"
   },
   "outputs": [],
   "source": [
    "#inspect results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z0KxvgpvS1A0",
   "metadata": {
    "id": "Z0KxvgpvS1A0"
   },
   "source": [
    "# Homework\n",
    "Now that you've learned the essentials of training, let's take a moment to reflect on what we've learned, augment our knowledge, and avoid some known pitfalls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p7ixNjI-TFa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Tokenizers: Verifying your understanding\n",
    "\n",
    "#@markdown Make sure to run all the cells in the `Aside on Tokenizer functionality`\n",
    "#@markdown section to make sure that you understand the encoding and decoding\n",
    "#@markdown functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XE3dw8M3TkfO",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Updating our tokenization function\n",
    "#@markdown Using the HF API, HF course, and Tunstall text\n",
    "#@markdown determine how you would pad each input during tokenization.\n",
    "#@markdown What methods of padding and truncation are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TSSgX61iUCbk",
   "metadata": {
    "cellView": "form",
    "id": "TSSgX61iUCbk"
   },
   "outputs": [],
   "source": [
    "#@title Expanding our knowledge of Datasets `map` method\n",
    "#@markdown What if we wanted to remove all html from our\n",
    "#@markdown data prior to tokenization? We can do this with the map\n",
    "#@markdown of Datasets. Use the following resource from the\n",
    "#@markdown [HuggingFace Course](https://huggingface.co/course/chapter5/3?fw=pt#the-map-methods-superpowers) to understand how one might\n",
    "#@markdown go about doing this. Implement this here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mfwIG2r3U-om",
   "metadata": {
    "id": "mfwIG2r3U-om"
   },
   "source": [
    "## Training Arguments and the Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IACwqovwVdTS",
   "metadata": {
    "cellView": "form",
    "id": "IACwqovwVdTS"
   },
   "outputs": [],
   "source": [
    "#@title Model metrics\n",
    "#@markdown Let's say that we wanted to see the precision and recall\n",
    "#@markdown for each of the individual classes rather than the `macro` averaging\n",
    "#@markdown as we saw in our current `compute_metrics` function we've written.\n",
    "\n",
    "#@markdown Using the same sklearn functions (or not, but sklearn may make it easier),\n",
    "#@markdown return the precision and recall for each individual class label in addition\n",
    "#@markdown to the macro scores. Recall that what is returned from the `compute_metrics`\n",
    "#@markdown function must be a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-3pwBcDVYgQp",
   "metadata": {
    "cellView": "form",
    "id": "-3pwBcDVYgQp"
   },
   "outputs": [],
   "source": [
    "#@title TrainingArguments parameters\n",
    "#@markdown We've logged, saved, and evaluated at each epoch. However,\n",
    "#@markdown if we have an extremely large dataset, seeing one or more of these\n",
    "#@markdown at the end of each epoch (e.g., if it takes 3 hours to make it through\n",
    "#@markdown a single epoch) may conflict with our desire to monitor our model training.\n",
    "\n",
    "#@markdown 1. Using the TrainingArguments API, change your model to log, evaluate, and save\n",
    "#@markdown every 200 steps rather than every epoch.\n",
    "#@markdown 2. How does this change your checkpointing directories?\n",
    "#@markdown 3. How does this influence the intervals of evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd89a2-bf3c-453a-8b53-50acce211130",
   "metadata": {
    "id": "f8bd89a2-bf3c-453a-8b53-50acce211130"
   },
   "source": [
    "## Your research project\n",
    "You've successfully trained a model - great job!! Now, let's focus on what YOU need to do for your task. What is the task that best describes what you're after? Using the [Transformer Notebooks](https://huggingface.co/docs/transformers/notebooks) and use the `Open in Colab` badge, explore what this task looks like. Note that even if your modality is different, you may be able to directly still use these notebooks with a few changes!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "thJhDvdZF-3U",
    "d0a371ec-98f5-4be7-b085-a2eed2f9c3d3",
    "d558ecf4-e35b-4afa-a1aa-ca16e86ab432",
    "15655b8b-45bb-4c3c-8ad8-dcd869beda5d",
    "08845526-78fb-4096-bb4b-1ca13c7eda12",
    "3da664a0-b63c-450a-ae74-bab101d55ea1",
    "oXe8fUReQyUu",
    "b6ba1189-3e5f-42ae-bfae-e79f85a439f5",
    "94abc5f1-076e-4167-9c85-26d77404797f",
    "Z0KxvgpvS1A0",
    "f8bd89a2-bf3c-453a-8b53-50acce211130"
   ],
   "include_colab_link": true,
   "name": "1-text-simple-classification-training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
